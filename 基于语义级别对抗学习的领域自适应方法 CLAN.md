# 基于语义级别对抗学习的领域自适应分割方法

## 基于边缘分布对齐的对抗网络

关注的主要问题：**无监督域自适应(UDA)问题**，即给定源数据 $X_s$以及对应的像素级标签 $Y_S$，和没有标签目标域数据 $X_T$，方法的目标是学习一个模型 f，**它可以正确地预测目标域数据 $X_T$的像素级标签。**

传统对抗学习的方法有效地提升了模型泛化能力，但这一类方法存在一个先天的 不足：当训练收敛，生成网络能够很好地欺骗判别网络时，它只是对两个领域的边缘分布（Marginal Distribution）进行了对齐（即 P($F_s$) ≈ P ($F_t$), 其中 $F_s$和 $F_t$分别表示源域和目标域中的数据），而忽略了两个领域中相对应的语义类别之间的联合概率分布对齐（即 P($F_s$, $Y_s$) 不等于P ($F_t$, $Y_t$), 其中 $Y_s和 Y_t$表示像素的类别）。因此，传统对抗学习方法在实际训练过程中可能会导致那些已经与源域中的语义对齐很好的目标域像素被映射到一个不正确的语义类别。特别是当使用较大的对抗损失权重训练网络时，这种副作用会变得更为严重，称之为 “负迁移” 现象。

<img src="https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650458300538.png" alt="uTools_1650458300538" style="zoom:50%;" />

灰色箭头的大小表示对抗性损失的权重，**传统的对抗性学习在追求边际分布对齐时忽略了语义一致性，全局移动导致良好对齐的特征（类别 A）映射到错误的语义上，造成负迁移。负迁移现象是导致模型在目标域性能下降的一个关键原因**,

## 基于语义级别对齐的对抗网络

### 核心思想

**CLAN 的核心思想分为两个方面。一方面，算法确定那些已经在源域和目标域之间已经语义对齐的像素，并保护这种类别对齐不受对抗学习的副作用影响。另一方面，算法找到在两个域之间分布不同的类，这些类需要利用对抗学习来完成对齐，因此需要在训练中增加了对抗损失的权重。**

### 协同训练

协同训练是**半监督学习**的一个分支。学习者在两种相互冗余的视角上完成训练，通过视角之间的协同作用对未标注的数据预测高置信度的标签。与传统的单视角训练方法不同，基于协同训练的方法使用两个分类器作为不同的视角对特征进行分类。当两个视角给出的预测一致时，则可认为此预测是准确的，可信度高的；而当两个视角的预测不一致时，可认为该预测不准确，可信程度低。

**伪标签的定义：**

其中，高置信度的预测结果可以作为伪标签使用，进一步使网络能够通过有监督学习的方式，直接从目标领域获得知识。协同训练的核心要求是要两个充分冗余的视角。在深度学习的框架下，“视角”这一概念是通过基于卷积神经网络的分类器来实现的，而 “充分冗余” 是指两个视角的判断依据需完全不同。

卷积就相当于一个眼睛

### 网络结构

![uTools_1650546664131](https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650546664131.png)

**文字叙述**

它由生成器 G 和判别器 D 组成。**G 可以是任何基于 FCN 的分割网络**，**D 是一个基于 CNN 的二进制分类器**，具有全卷积输出，根据标准的协同训练算法，将生成器 G 分为特征提取器 E 和两个分类器C1和 C2（**这里面的特征提取器是不是就相当于VAE里面的编码器**）。

E 从输入图像中提取特征，C1和 C2将 E 提取的特征分类为预定义的语义类之一(这里其实是核心：对不同的语义类进行分类)，如车辆、树木和道路。根据协同训练的要求，通过余弦距离损失引导 C1和C2的权重向量正交。这将为网络提供不同的视角来对每个特性进行语义预测。

最终的预测图 p 由两种不同的预测张量 p(1)和 p(2)相加得到的，这里称 p 为综合预测。给定$X_s$中的源域图像 $x_s$，特征提取器 E 输出一个特征向量，它紧接着被输入到分类器 C1和 C2中，以生成像素级的综合预测 p。一方面，p 用于计算在 $Y_s$中的真实标签 $y_s$的监督下的多分类交叉熵损失。另一方面，p 被输入到 D 中，以产生对抗损失。给定 $X_t$中的目标域图像$ x_t$，类似于源域流，算法将它输入到 G 并输出一个综合预测 p。与源数据流不同的是，算法还从 p(1)和 p(2)中生成一个预测差异图，表示为 $M(p^{(1)}p^{(2)})$，其中 M(··) 表示某个适当的距离度量，用于度量 p(1)和 p(2)之间的像素级差异。

### 损失函数

CLAN 的训练目标包括三项损失函数，即**分割损失、权重差异损失和自适应对抗损失**。

**分割损失**

给定一个源域的图像 $x ∈ X_S$，图像大小为$ 3 × H × W$；以及一张对应的真实标签 $y ∈ Y_S$，标签大小为 $C × H timesW$，其中 C 是类别的数目。第一项分割损失，也称作**多类交叉熵损失**:这里的多类交叉熵损失在以前的论文笔记中给出过详细的解释

<img src="https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650547333689.png" alt="uTools_1650547333689" style="zoom: 50%;" />

其中 $p_{ic}$表示在第 i 个像素上对类别 c 的预测概率，$y_{ic}$表示数据集中像素 i 的真实类别：如果第 i 个像素属于类别 c, 那么 $y_{ic}$= 1，反之 $y_{ic}$= 0

**权重差异损失**

依据标准的协同训练算法准则，C1和 C2这两个分类器应该尽可能冗余甚至正交，即具有完全不同的参数，**以便对一个特征向量提供两个不同的视角进行分类**

否则，协同训练就会退化为一般的有监督训练。**算法通过最小化两个分类器参数向量的余弦相似度来增强它们的卷积层的权值的差别。**

<img src="https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650547852078.png" alt="uTools_1650547852078" style="zoom:60%;" />

w1和w2代表分类器的两个参数

**语义级对抗性损失（传统对抗损失的升级版）**

先来图

![uTools_1650547954217](https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650547954217.png)

其中 p(1)和 p(2)分别表示由分类器 C1和 C2作出的预测，M(··) 表示余弦距离，超参数 $λ_{local}$控制对抗性损失的自适应权值

### 总的损失函数

![uTools_1650548073551](https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650548073551.png)

这里训练的方式和传统的训练方式是一样的

## 对于CLAN和传统的方法对比

**主要区别在两点**

### 分类器的权重差异损失

**分类器的权重差异损失（协同训练）鼓励特征提取模块 E （生成器）学习领域间的不变特征，而不是学习域特定特征，如光照变化等。**

在网络中，分类器 C1和 C2由权重差异损失的影响，会尽可能提取不同的视觉特征，而特征提取模块 E 又要确保在不同的视觉特征下都要给出正确的分割结果。

这两种力量的对抗就导致了实际上**要求 E 应该跨源和目标域提取像素的基本语义信息**，而语义信息正是两个域之间共享的不变特征。如果没有权重差异损失（协同训练），这两种力量的对抗就会消失消失，即 E 学习领域间不变信息的能力也会减弱。

**这里的不变特征也是上文中提到的联合分布，就是学习两个域中的联合分布**

在跨域语义分割任务中，**两个域在视觉级别上有很大差异，但在语义级别上有重叠**。如果 E 中的 C1和 C2使
用视觉级别特征作为输入，它们在目标域中的预测将是不准确的，并且往往是不同的，这将使模型的对抗损失权重急剧增大，从而受到巨大的对抗损失惩罚。在不同的阶段采用不同的算法。 **因此，一旦算法收敛，C1和 C2将使用语义级特征而不是视觉级特征进行输入。也就是说，E 被鼓励学习域不变语义**。

其实这里已经证明了标题：**权重差异损失是提高领域自适应能力的隐性促进因素**

### 语义对抗损失

**算法使用自适应权值$ [λ_{local}M(p^{(1)}p^{(2)}) + ϵ]$ 扩展了传统的对抗性损失。**

一方面，当 $M(p^{(1)}p^{(2)})$ 较大时，同一类的特征在两个域之间没有类似的联合分布：它们存在语义不一致的问题。因此，权重会主要分配在未对齐的特征上，为了鼓励 G 欺骗 D。

另一方面，当 $M(p^{(1)}p^{(2)})$ 较小时，联合分布在域之间会有较大的重叠，**说明语义不一致问题不严重**。在这种情况下，**G 往往忽略 D 的对抗性惩罚** 。从 D 的观点来看**，自适应权重的引入鼓励 D 从语义不一致的示例中提取更多的知识，而不是从那些对齐良好的类中。**因此，在对抗训练中，CLAN 能够提高语义级别的域间一致性程度，这是影响自适应能力的一个重要因素。

对抗网络可以生成一个大致良好的分割结果。

原因是传统的全局对抗策略倾向于给所有像素分配保守的预测类别，导致一些罕见类别像素被预测到其他常见类，从而导致那些不常见的特征被负迁移。

**但是CLAN可以大大减少这种结果**

## 精华：理论证明

**定理： H 表示假设函数集, S 和 T 分别表示源域和目标域, Ben-David 等人从理论上证明了在无监督领域自适应的设定下，模型在目标域上的错误率期望上界 $ϵ^T(h)$可表示为以下三个项的累加和**

<img src="https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650598580879.png" alt="uTools_1650598580879" style="zoom:50%;" />

其中 $ϵ^S(h) $表示模型在源域的错误率期望。因为源域是有真实标签的，所以该项通常可以由已有的监督学习方法进行最小化，因此该项一般较小。第二项 $d_H(S, T )$ 表示源域和目标域的分布在距离度量 $h ∈ H $下的距离。λ 表示模型在两个域中的理论最小误差的期望，一般来说非常小可以忽略。从 Ben-David 的领域适应理论可以看出，**减少两个域之间的在某种距离度量下的分布距离是至关重要的**



**推论:正交分类器 C1和 C2将 h 限制为假设函数集 H 的一个子集**

证明 : 公式 3.8**希望在假设空间 H 内找到一个假设函数 h 来刻画两个域之间距离 $d_H(S, T )$ 的上界，同时也希望训练一个网络 G，在假设函数 h 的前提下最小化 $d_H(S, T )$ 已达到领域自适应的目的**。数学上可以用 minimax 运算符来替换掉sup 运算符。公式 3.8 可以重新写成如下形式

![uTools_1650598869410](https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650598869410.png)

如果将 h 看作是一个领域判别器，公式. 3.9实际上完全符合一个对抗学习的标准模式。

**3.9存在的问题**

这种对抗学习的模式**只能保证全局边缘对齐而不能保证语义间的联合分布对齐**。因此，这个针对判别器的函数搜索空间过于宽松。

**解决办法**

在引入了两个正交分类器后，算法将联合概率分布 $P(x, y)$ 也纳入了考虑范围：

<img src="https://cdn.jsdelivr.net/gh/junsuyiji/tuchang@master/uTools_1650599046757.png" alt="uTools_1650599046757" style="zoom: 50%;" />

其中 $K(G(x), y) $表示将样本 x 预测为标签 y 的置信度。

在 CLAN 方法中, 这种置信度可以表示为两个正交分类器 C1和 C2的预测一致性。

对于源域而言，这种置信度接近于 1，因为模型总能通过真实标签的监督来学习最正确的预测结果。而对于目标域而言，不同于传统的对抗学习方法，CLAN 除了需要生成类似于源域的分割结果之外，还需要额外训练$ K(G(x), y) → 1 $来欺骗判别器。

可以看出，相比于传统的只通过生成结果来判断数据来源的判别器 h 而言, $\hat{h}$ 是一个更严格的判别函数，**它不仅需要生成器在目标域图像上分割出类似于源域的分割结果，还需要对分割结果有较高的置信度，因此能引导域间的全局对齐和语义级别对齐。**

**这也就相当于算法在原始的函数空间 H 中生成了一个更为严格的子集$\hat{H}$，对于判别器的训练均在这个子集内完成： $\hat{h} ∈\hat{H} ⊆ H$, 在该函数子集中，边缘分布对齐和联合分布对齐可以同时完成**。