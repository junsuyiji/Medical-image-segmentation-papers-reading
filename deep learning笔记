## 深度学习综述

手写数字识别已经成为了dr的hello world

花书：深度学习，一本好书，李航的统计方法，还有西瓜书

最基本的核心算法：反向传播

应用：卷积神经网络，循环神经网络

最好的是能用：简单的方式理解复杂的事物

relu比sigmoid要好，具体细节百度一下



ai可以看懂这个世界，这是cv上神经网络强过传统方法

自然语言处理 

word embedding：将文本转换为数值数据，可以表达意思

传统是one hot enbedding:仅仅代表位置

还是那一句话ai可以看懂这个世界

word2vec：词向量

rnn：带有存储功能的神经网络

lstm：优化rnn

未来：
非监督学习
强化学习 
生成对抗网络

强化+对抗：这个东西解释清楚，好在还不太需要太多数学。我来试图解释一下。GAN实际上可以看成是一种具有特殊损失函数的神经网络。这个损失函数特殊到其本身也是一个神经网络，更特殊的是，网络的参数也会发生变化。这个变化的高明之处是，随着原始网络的进化，作为损失函数的网络也会变得更强，以避免原始网络能够对这个损失函数进行很好的拟合。早期的RL与这个东西没有太多相似性，只是纯粹对于策略的学习。但是RL中间有一个很关键的点是，它天然就是一个损失函数不容易求的过程。RL最难的是只知道阶段性奖励，却要求每一步能够做出全局下的最优解。换言之，这要求我们在每一步下都能够知道全局下的最优损失函数是什么。过去人们经常用的是随机性的方法，但是最近的强化学习发现使用另一个网络来学习评价会更好。也就是所谓的演员评论家算法。所以这个方法的本质也是通过另一个网络的学习，增强前一个网络损失函数的准确度。因此，从本质上说，它与现在的生成对抗网络是一致的。只需要意识到他们的本质都是使用神经网络，来拟合另一个神经网络的损失函数。所以我认为两个东西长的很像，大概是人们对于神经网络的理解，又上了一层。可能是一种演化的必然吧。

非监督学习

监督学习

自监督学习
