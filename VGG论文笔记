arxiv：可以先把idea发在这个网站上

论文研究背景和成果：使用小卷积核捕捉更细节的信息；多尺度：即训练和测试的时候使用网络的不同尺度，来增强
网络的泛化能力

作者还研究了网络深度对结果的影响

VGG由于结构简单，提取特征能力强，所以应用广泛

研究方法：对比实验一定要做好，修改了上面，改后结果变得怎么样，

对于同一个网络，多尺度训练可以提升网络的精度

dense evluation&multi-.crop两种测试方式联合使用效果最好
那么dense evaluation 和 multi-crop（多尺度数据）又是什么？
dense evaluation：就是将最后的全连接层改为1x1的卷积（FCN的启示，感兴趣的同学可以去了解一下），得出一个预测的score map，再对结果求平均
multi-crop 多尺度数据：即对图像进行多样本的随机裁剪，然后通过网络预测每一个样本的结构，最终对所有的结果求平均。

模型融合可以提升精度

论文结论
1.在一定范围内，通过增加深度能有效地提升网络性能：
2.最佳模型：VGG16,从头到尾只有3x3卷积与2x2池化，简
洁优美；
3.多个小卷积核比单个大卷积核性能好（与alxnet对比可知)：
4.AlexNet曾经用到的LRN层并没有带来性能的提升，因此在
其它组的网络中均没再出现LRN层：
5.尺度抖动scale jittering(多尺度训练，多尺度测试)有利
于网络性能的提升。

LRN全称为Local Response Normalization，即局部响应归一化层，LRN函数类似DROPOUT和数据增强作为relu激励之后防止数据过拟合而提出的一种处理方法。这个函数很少使用，基本上被类似DROPOUT这样的方法取代，见最早的出处AlexNet论文。

感受野：感受野(Receptive Field)的定义是卷积神经网络每一层输出的特征图 (feature map)上的像素点在输入图片上映射的区域大小。再通俗点的解释是，特征图上的一个点跟原图上有关系的点的区域。

为什么使用3*3的卷积核？
1深度更深并增加了非线性3个3*3的卷积核感受野与一个7*7卷积核感受野等效，但是三个3*3卷积之间加入了激活函数，与仅使用一个7*7卷积核相比，深度更深且增加了非线性。
02
参数量减少假设输入数据通道大小为C
3个C通道的3*3的卷积核参数量为3*(C*3*3*C)“=27C*C1个C通道的7*7卷积核参数量为C*7*7*C=49C*C

1*1的卷积核的作用？
1种为决策增加非线性因素的方式
调整网络维度扩维或者缩小维度
eg:mobilenet使用1*1卷积核来扩维
resnet使用1*1卷积核来减小维度
